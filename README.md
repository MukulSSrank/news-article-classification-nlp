# ğŸ“° News Article Classification (NLP)

This project builds a **multi-class text classification model** to categorize news articles into topics such as **sports, politics, technology, business**, etc., using Natural Language Processing (NLP) and machine learning.

---

## ğŸ¯ Objective

Develop a machine learning model that can automatically assign each news article to the most likely **category** based on its text content.

Example categories:

- `sports`
- `politics`
- `technology`
- `business`
- (and others, depending on the dataset)

---

## ğŸ—‚ï¸ Dataset

- **Dataset name:** `data_news`
- **Records:** ~10,000+ news articles (edit this as per your actual data)
- **Target variable:** `category` â†’ article topic/label

**Main columns:**

- `text` â€“ the full content of the news article  
- `category` â€“ the label for each article (e.g., sports, politics, tech)

---

## ğŸ›  Tech Stack

- **Language:** Python  
- **Environment:** Jupyter Notebook  

**Libraries:**

- Data handling: `pandas`, `numpy`
- NLP & preprocessing: `nltk`, `re`, `string`
- Machine learning: `scikit-learn`
- Visualization: `matplotlib`, `seaborn`

---

## ğŸ”„ Project Workflow

### 1ï¸âƒ£ Data Cleaning & Preprocessing

Applied the following preprocessing steps to the `text` column:

- Lowercased all text  
- Removed:
  - Punctuation  
  - Numbers  
  - Special characters  
  - Extra whitespace  
- Tokenization (splitting text into words)  
- Stopword removal using **NLTK**  
- Lemmatization / stemming to reduce words to their base form  

This prepared clean text suitable for feature extraction.

---

### 2ï¸âƒ£ Exploratory Data Analysis (EDA)

- Checked dataset shape and basic info  
- Verified if there were **missing values**  
- Analyzed **class distribution** across categories (sports, politics, tech, etc.)  
- Visualized:
  - Category counts (bar plots)  
  - Common words or phrases in each category  

---

### 3ï¸âƒ£ Feature Extraction

Converted preprocessed text into numerical features using:

- **TF-IDF (Term Frequencyâ€“Inverse Document Frequency)**  
  - Uni-grams and bi-grams

Optionally, additional ideas (if implemented):

- Bag-of-Words representation  
- Word embeddings like **Word2Vec** / **GloVe**

The main representation for modeling in this project is **TF-IDF vectors**.

---

### 4ï¸âƒ£ Model Development

Trained and compared multiple machine learning models for **multi-class classification**:

- Logistic Regression  
- Multinomial Naive Bayes  
- Linear Support Vector Machine (SVM)  

Steps followed:

- Trainâ€“test split (e.g., 80% train, 20% test)  
- Cross-validation to ensure robustness  
- Hyperparameter tuning for the best model using grid search / manual tuning  

---

### 5ï¸âƒ£ Model Evaluation

Evaluated model performance using:

- **Accuracy**
- **Precision**
- **Recall**
- **F1-score** (macro and weighted)
- Confusion matrix for class-wise performance

Visualizations included:

- Confusion matrix heatmap  
- Category-wise precision/recall/F1 comparison  
- Support (number of samples per class)

---

## ğŸ“Š Example Results (Replace with Your Actual Metrics)

> These are placeholder numbers â€“ update them from your notebook.

- **Best model:** Linear SVM / Logistic Regression with TF-IDF  
- **Test accuracy:** ~**85â€“88%**  
- **Macro F1-score:** ~**0.84â€“0.87**  

**Key insights:**

- **Sports** articles were classified with the highest accuracy due to distinct vocabulary (e.g., â€œmatchâ€, â€œgoalâ€, â€œtournamentâ€, â€œscoreâ€).  
- Some misclassification occurred between **politics** and **business** articles because of overlapping terms (e.g., â€œpolicyâ€, â€œbudgetâ€, â€œmarketâ€).  
- Using **bi-grams** improved performance by capturing meaningful phrases like â€œprime ministerâ€, â€œstock marketâ€, â€œartificial intelligenceâ€, etc.

---

## ğŸ“ Files in This Repository

- `NLP2Project.ipynb` â€“ main Jupyter Notebook containing:
  - Data loading  
  - Text preprocessing  
  - Feature extraction (TF-IDF)  
  - Model training and evaluation  

- `data_news.csv` (optional) â€“ a small sample of the news dataset for demo

- `reports/News_Classification_Report.pdf` (optional) â€“ summary report of the project

---

## ğŸš€ How to Run the Project

1. **Clone the repository:**

   ```bash
   git clone https://github.com/MukulSSrank/news-article-classification-nlp.git
   cd news-article-classification-nlp
